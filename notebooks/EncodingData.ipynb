{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 22 21:18:07 2018\n",
    "\n",
    "@author: Adrian\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, time\n",
    "import _sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "def db_to_csv(query):\n",
    "    conn = _sqlite3.connect('2016_11.db')\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    data.to_csv('ads.csv',sep=';')\n",
    " \n",
    "def photos_parser(photo_sizes):\n",
    "    photo_sizes=photo_sizes.replace('\"\"','\"')\n",
    "    data=json.loads(photo_sizes)\n",
    "    num_of_photos=len(data)\n",
    "    return(num_of_photos)\n",
    "\n",
    "def assign_num_of_photos(data):\n",
    "    all_photos = data['photo_sizes'].apply(str)\n",
    "    num_of_photos = []\n",
    "    for i in range(len(all_photos)):\n",
    "        try:\n",
    "            num_of_photos.append(photos_parser(all_photos[i]))\n",
    "        except:\n",
    "            num_of_photos.append(0)\n",
    "    return(pd.DataFrame({'num_of_photos': num_of_photos}))\n",
    "\n",
    "\n",
    "def assign_time_since_creation(data):\n",
    "    time_since_creation = pd.DataFrame({\"time_since_creation\": (pd.to_datetime(data['sorting_date'])-pd.to_datetime(data['created_at_first'])).astype('timedelta64[h]')})\n",
    "    time_since_creation[time_since_creation<0]=0\n",
    "    return(time_since_creation)\n",
    "\n",
    "def assign_user_and_city(data):\n",
    "    city_cnt = Counter()\n",
    "    user_cnt = Counter() \n",
    "    for city in data['city_id']:\n",
    "        city_cnt[city] += 1\n",
    "    for user in data['user_id']:\n",
    "        user_cnt[user] += 1    \n",
    "    city_ads = data['city_id'].apply(lambda x: city_cnt[x])\n",
    "    user_ads = data['user_id'].apply(lambda x: user_cnt[x])\n",
    "    user_and_city = pd.DataFrame({'city_ads': city_ads, 'user_ads': user_ads})\n",
    "    return(user_and_city)\n",
    "\n",
    "def assign_traffic_level(data):\n",
    "    l = np.zeros(len(data))\n",
    "    twos=np.array((pd.to_datetime(data['sorting_date']).dt.time >= time(18,00)) & (time(22,00) >= pd.to_datetime(data['sorting_date']).dt.time))\n",
    "    l[twos]=2\n",
    "    ones=np.array((pd.to_datetime(data['sorting_date']).dt.time >= time(8,00)) & (time(18,00) >= pd.to_datetime(data['sorting_date']).dt.time))\n",
    "    l[ones]=1\n",
    "    return(pd.DataFrame({'traffic_level': l}))\n",
    "\n",
    "def assign_params_parser(params):\n",
    "    params = str(params)\n",
    "    par_list=re.split(\"<=>|<br>\", params)\n",
    "    parsed_params=dict()\n",
    "    if 'price' in par_list:\n",
    "        par_list[par_list.index('price')] = \"price_type\"\n",
    "    for i in range(0, int((len(par_list)/2))):\n",
    "        parsed_params[par_list[2*i]]=par_list[2*i+1]\n",
    "    return parsed_params\n",
    "\n",
    "def assign_params(data):\n",
    "    price_type, price, state, Type = ([] for i in range(4))\n",
    "    for i in range(len(data)):\n",
    "        params = str(data['params'][i])\n",
    "        par = params_parser(params)\n",
    "        try:\n",
    "            price_type.append(par['price_type'])\n",
    "        except KeyError:\n",
    "            price_type.append(0)\n",
    "        try:\n",
    "            price.append(par['price'])\n",
    "        except KeyError:\n",
    "            price.append(0)\n",
    "        try:\n",
    "            state.append(par['state'])\n",
    "        except KeyError:\n",
    "            state.append(0)\n",
    "        try:\n",
    "            Type.append(par['type'])\n",
    "        except KeyError:\n",
    "            Type.append(0)\n",
    "    params = pd.DataFrame({'price_type': price_type,\n",
    "                           'price': price,\n",
    "                           'state': state,\n",
    "                           'type': Type})\n",
    "    return(params)\n",
    "   \n",
    "def assign_promo_level(data):\n",
    "    promo_lvl = np.zeros(len(data))\n",
    "    promo_lvl[data['paidads_id_index']==3] = 1\n",
    "    promo_lvl[data['paidads_id_index']==4] = 2\n",
    "    promo_lvl[data['paidads_id_index']==85] = 3\n",
    "    return(pd.DataFrame({'promotion_level':promo_lvl}))\n",
    "    \n",
    "def process_data(df, df_queries):\n",
    "    params = assign_params(df)\n",
    "    time_since_creation = assign_time_since_creation(df)\n",
    "    traffic_level = assign_traffic_level(df)\n",
    "    num_of_photos = assign_num_of_photos(df)\n",
    "    promo_level = assign_promo_level(df)\n",
    "    searches = assign_queries(df, df_queries)\n",
    "    df = df.drop([ 'id', 'params', 'title','sorting_date', 'created_at_first', 'photo_sizes', 'paidads_valid_to', 'paidads_id_index'],1)\n",
    "    df = pd.concat([df, params, time_since_creation, traffic_level, num_of_photos, promo_level, searches], axis=1)\n",
    "    df.loc[df['price_type']==\"free\",['price']]=0\n",
    "    return(df)\n",
    "####################################################################\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "model_raw='model_raw.csv'\n",
    "sorted_ad_hits = 'sorted_ad_hits.csv'\n",
    "sorted_empy_sessions = 'sorted_empy_sessions.csv'\n",
    "\n",
    "\n",
    "obj = s3.get_object(Bucket='2016-11', Key=model_raw)\n",
    "data_raw = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=';',dtype='unicode')\n",
    "\n",
    "obj = s3.get_object(Bucket='2016-11', Key=sorted_ad_hits)\n",
    "sorted_at_hits = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=';',dtype='unicode')\n",
    "\n",
    "obj = s3.get_object(Bucket='2016-11', Key=sorted_empy_sessions)\n",
    "sorted_empty_sessions = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=';',dtype='unicode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_converted = convert_data(data_raw)\n",
    "data = pd.concat([data_converted, sorted_at_hits, sorted_empty_sessions],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETag': '\"a445757a99d1563e5b98541d6e84605b\"',\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '0',\n",
       "   'date': 'Sun, 25 Feb 2018 17:39:40 GMT',\n",
       "   'etag': '\"a445757a99d1563e5b98541d6e84605b\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'x-amz-id-2': '2zX6O9hTfZTxyfnbT+xV+i9C0fAnh2J+9FYY57DX1uRACSWln2GpHcDbZSsz3aMTXFYLpGH1yzg=',\n",
       "   'x-amz-request-id': '05C54B7D46817454'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HostId': '2zX6O9hTfZTxyfnbT+xV+i9C0fAnh2J+9FYY57DX1uRACSWln2GpHcDbZSsz3aMTXFYLpGH1yzg=',\n",
       "  'RequestId': '05C54B7D46817454',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('data.csv', 'rb')\n",
    "s3.put_object(Bucket='2016-11', Key='data.csv', Body=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
